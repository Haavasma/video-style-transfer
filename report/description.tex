\section{Group Members}
\begin{outline}
\1 Tobias Meyer Andersen
\2 tobiaand@stud.ntnu.no
\1 Kjerand Evje
\2 kjerande@stud.ntnu.no
\1 Dilawar Mahmood
\2 dilawarm@stud.ntnu.no
\1 Håvard Stavnås Markhus
\2 haavasma@stud.ntnu.no
\end{outline}
\section{Project Description}
For the machine learning project in TDAT3025, we want to explore and implement style transfer with machine learning when utilized on videos. We want to look at different machine learning and optimization techniques for transforming videos to a particular style, whether it is Van Gogh or anime.\newline\newline
The main obstacle to this problem is the amount of computing power it takes to convert a video to a given style. Gatys, Ecker, and Bethge first introduced neural style transfer in 2015 \cite{Gatys:1}, and since then, new methods have emerged. We want to look at how different machine learning models, neural networks, loss functions, etc. perform in terms of efficiency of styling the video and the stylized result itself. Simultaneously, we will be implementing these algorithms and try to combine different elements from the algorithms to make relatively fast and useful machine learning models for generating stylized videos.