The introduction gave the following purpose of the paper; "to compare existing ways of implementing video style transfer and to implement our own versions based on these". In the "Results" and "Discussion" chapter we went through the videos produced by our implementations and briefly discussed what the advantage and disadvantage of each of them were.\newline\newline 
A short recap: Gatys \cite{Gatys:1} original paper is slow, and produces a lot of noise in video, although it does work with any style. This was the foundation for Ruder et al. \cite{Ruder:1} who added Deepflow to avoid most of the noise, at the expense of more compute power. This procedure is so costly that it appears to be not out of the question to sacrifice the flexibility of style (train on a single style) and use a neural net to approximate the transformation. This quite different approach can make videos of decent artistic quality that can work for real-time applications, it was first described in Johnson et al. \cite{Johnson:1}. Further we implemented the paper by Huang et al. \cite{Huang:1}. Based on the artistic quality of the style-transferred images we believe it to be true that style is better represented by a distribution than a Gram Matrix, as using Wasserstein in the loss functions made for better results.\newline\newline 
Finally we wanted to return to the original question of style transferring videos. Therefore in our own implementation we did to Huangs paper \cite{Huang:1} what Ruder \cite{Ruder:1} did to Gatys paper \cite{Gatys:1}, turn a paper describing a new image style-transfer technique into a video style-transfer by adding temporal loss and warping with Deepflow to produce more stable results. This gave, in our opinion, the best artistic quality, at the vast cost of computation.\newline\newline
Another original implementation was our implementation of Johnson's paper \cite{Johnson:1}. Our contribution was to combine their neural net with Instance Normalization, instead of the Batch Normalization. We have described the reasons for doing so in Section \ref{sec:instance_normalization}. Therefore we ended up with two original implementations: one with the best possible artistic quality, at the cost of computation and another with very fast computing times, at the cost of flexibility.
\newpage